GPUS: '0'
OUTPUT_DIR: 'output' # automatically change it to OUTPUT_DIR/yaml file name/timestamp /, which will store the model, log, tensorboard, and so on
WORKERS_PARALLEL: 16
WORKERS_DATALOADER: 0

DATASET:
  ROOT_DIR: '../data'
  FRAME_STRIDE: 3 # (@Frozen = 3, if 'USE_IMAGE_MODE' is 'downscaled')
  WINDOW_LENGTH: 20 # FRAME_STRIDE=1, WINDOW_LENGTH=50, is best, so when FRAME_STRIDE=3, WINDOW_LENGTH=20 is good (@Frozen = 20, if 'USE_IMAGE_MODE' is 'downscaled') 
  PADDING_MODE: 'repeat' # 'zero' or 'repeat'
  ANNOTATION_STRIDE_TRAIN: 1
  ANNOTATION_STRIDE_VAL: 1
  ANNOTATION_STRIDE_TRAINVAL: 1
  MIN_JOINT_NUM: 10 # when annotated joints are less than this, the data will be ignored (@Frozen = 10, if 'USE_IMAGE_MODE' is 'downscaled') 
  USE_ANNOTATION_MODE: 'annotation' # 'annotation' or 'automatic' or 'both' (@Frozen='annotation', if 'USE_IMAGE_MODE' is 'downscaled') 
  USE_IMAGE_MODE: 'downscaled' # 'none' or 'fullsize' or 'downscaled'
  TAKE_NUM_TRAIN: 10
  TAKE_NUM_VAL: 10
  TAKE_NUM_TEST: 10
  INPUT_DIM: # will be changed in utils_dataset.py/pre_process_camera_pose but won't take effect when called by multi-threading
  
PRE_PROCESS:
  INPUT_IMU_MODE: 'R_and_T' # 'T' or 'R_and_T' or 'imu_point' or 'imu_vector' or 'imu_vector_xyz'
  INPUT_IMU_DIFF_INTERVAL: 1
  INPUT_IMAGE_MODE: 'none'
  TARGET_MODE: 'camera' # 'camera' or 'world'

MODEL:
  BASELINE:
    EMBED_DIM: 256
    NHEAD: 8
    NUM_LAYER: 3
    DROPOUT: 0

OUTPUT_HEAD:
  MLP:
    HIDDEN_DIM: 256
    DROPOUT: 0
  TRANSFORMER_DECODER:
    EMBED_DIM: 256
    NHEAD: 8
    NUM_LAYER: 3
    DROPOUT: 0.2 # TODO

SELECT_MODEL: 'BASELINE'
SELECT_OUTPUT_HEAD: 'MLP' # 'MLP' or 'TRANSFORMER_DECODER'

TRAIN:
  FLAG_USE_TRAINVAL_DATASET: false # if true, use train and val dataset to train the model, otherwise use only train dataset
  PRETRAINED_MODEL: 
  BATCH_SIZE: 128
  SHUFFLE: true
  LOSS_CRITERION: 'MPJPELoss'
  OPTIMIZER: 'AdamW' # 'Adam' or 'AdamW'
  LR: 0.0005 # origin 0.0005
  WEIGHT_DECAY: 0.001
  LR_MIN: 0.000001 # minimum learning rate

  BEGIN_EPOCH: 0
  END_EPOCH: 20
  SAVE_INTERVAL: 5  # save model every SAVE_INTERVAL epochs
  
VAL:
  BATCH_SIZE: 128
  LOSS_CRITERION: 'MPJPELoss'

TEST:
  BATCH_SIZE: 128